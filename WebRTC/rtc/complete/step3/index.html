<!DOCTYPE html>
<html>

<head>

<meta name="keywords" content="JavaScript, WebRTC" />
<meta name="description" content="WebRTC codelab" />
<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1">

<title>WebRTC codelab: step 3</title>

<style>
</style>

    <script src='js/lib/adapter.js'></script>

</head>

<body>

  <video id="localVideo" autoplay muted></video>
  <video id="remoteVideo" autoplay muted></video>

  <div>
    <button id="startButton">Start</button>
    <button id="callButton">Call</button>
    <button id="hangupButton">Hang Up</button>
  </div>

<script>
var localStream, localPeerConnection, remotePeerConnection;

var localVideo = document.getElementById("localVideo");
var remoteVideo = document.getElementById("remoteVideo");

var startButton = document.getElementById("startButton");
var callButton = document.getElementById("callButton");
var hangupButton = document.getElementById("hangupButton");
startButton.disabled = false;
callButton.disabled = true;
hangupButton.disabled = true;
startButton.onclick = start;
callButton.onclick = call;
hangupButton.onclick = hangup;

function trace(text) {
  console.log((performance.now() / 1000).toFixed(3) + ": " + text);
}

function gotStream(stream){
	trace("Received local stream");
	localVideo.src = URL.createObjectURL(stream);		// a consenso avvenuto video e audio del pc vengono azionati
	localStream = stream;
	callButton.disabled = false;
}

function start() {
	trace("Requesting local stream");			// appare una finestra per la richiesta di consenso ad utilizzare microfono e video del pc
	startButton.disabled = true;
	getUserMedia({audio:true, video:true}, gotStream, 
	function(error) {
		trace("getUserMedia error: ", error);
	});
}

function call() {
	callButton.disabled = true;
	hangupButton.disabled = false;
	trace("Starting call");
	// localStream Ã¨ lo stream definito nella funzione 'gotStream' (riga 53)
	if (localStream.getVideoTracks().length > 0) {	
		trace('Using video device: ' + localStream.getVideoTracks()[0].label);
// 'getVideoTracks' fa parte dell'intefaccia 'MediaStreamTrack' (vedi qui: http://dev.w3.org/2011/webrtc/editor/getusermedia.html#media-stream-track-interface-definition )
	}
  if (localStream.getAudioTracks().length > 0) {
    trace('Using audio device: ' + localStream.getAudioTracks()[0].label);	//'getAudioTracks' fa parte dell'interfaccia 'MediaStreamTrack'
  }

  var servers = null;

  localPeerConnection = new RTCPeerConnection(servers);
  trace("Created local peer connection object localPeerConnection");
  localPeerConnection.onicecandidate = gotLocalIceCandidate;

  remotePeerConnection = new RTCPeerConnection(servers);
  trace("Created remote peer connection object remotePeerConnection");
  remotePeerConnection.onicecandidate = gotRemoteIceCandidate;
  remotePeerConnection.onaddstream = gotRemoteStream;

  localPeerConnection.addStream(localStream);	// aggiunge lo stream 
// 'addStream' --> http://dev.w3.org/2011/webrtc/editor/webrtc.html#interface-definition
  trace("Added localStream to localPeerConnection");
  localPeerConnection.createOffer(gotLocalDescription,handleError);
// 'createOffer': metodo che genera un blob di sdp con le configurazioni di supporto per la sessione incluso la descrizione del MediaStream collegato alla RTCPeerConnection (riga 98), le opzioni codec/RTP/RTCP supportate e infine tutti i candidate raccolti dall'agente ICE. 

} // call

function gotLocalDescription(description){
  localPeerConnection.setLocalDescription(description);
  trace("Offer from localPeerConnection: \n" + description.sdp);
  remotePeerConnection.setRemoteDescription(description);
  remotePeerConnection.createAnswer(gotRemoteDescription,handleError);
}

function gotRemoteDescription(description){
  remotePeerConnection.setLocalDescription(description);
// 'setLocalDescription' --> http://dev.w3.org/2011/webrtc/editor/webrtc.html#interface-definition
  trace("Answer from remotePeerConnection: \n" + description.sdp);
  localPeerConnection.setRemoteDescription(description);
}


function gotRemoteStream(event){
  remoteVideo.src = URL.createObjectURL(event.stream);
  trace("Received remote stream");
}

function gotLocalIceCandidate(event){

  if (event.candidate) {
    remotePeerConnection.addIceCandidate(new RTCIceCandidate(event.candidate));
// 'addIceCandidate' -->  http://dev.w3.org/2011/webrtc/editor/webrtc.html#methods
    trace("Local ICE candidate: \n" + event.candidate.candidate);
  }
}

function gotRemoteIceCandidate(event){
  if (event.candidate) {
    localPeerConnection.addIceCandidate(new RTCIceCandidate(event.candidate));
    trace("Remote ICE candidate: \n " + event.candidate.candidate);
  }
}

function hangup() {
  trace("Ending call");
  localPeerConnection.close();
  remotePeerConnection.close();
  localPeerConnection = null;
  remotePeerConnection = null;
  hangupButton.disabled = true;
  callButton.disabled = false;
}

function handleError(){}
/*
22.355: Local ICE candidate: 
a=candidate:1590026637 1 udp 2122260223 169.254.123.195 65080 typ host generation 0
a=candidate:1590026637 1 udp 2122260223 169.254.123.195 56156 typ host generation 0
22.362: Remote ICE candidate: 
a=candidate:1590026637 1 udp 2122260223 169.254.123.195 65082 typ host generation 0
a=candidate:1590026637 1 udp 2122260223 169.254.123.195 56158 typ host generation 0
*/
</script>

</body>

</html>
